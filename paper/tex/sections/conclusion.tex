\section{Заключение}

В данной работе исследовалась задача дистилляции в глубоких сетях.
Был предложен метод дистилляции, который учитывает больше информации от учителя,
работает с разными архитектурами сетей и показывать лучшее качество, по сравнению с классическими методами.
Дистилляция проводилась с помощью максимизации взаимной информации между всеми слоями ученика и учителя.
Было подобранно вариационное распределение, с помощью которого можно максимизировать взаимную информацию,
предложен его вид для свёрточных и линейных слоёв моделей.
Были проведены эксперименты, показавшие эффективность предложенного метода.
Таким образом, показана и экспериментально доказана эффективность предложенного метода.