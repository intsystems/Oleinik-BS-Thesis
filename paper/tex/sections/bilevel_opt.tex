
\section{Вариационная максимизация информации}

Функция потерь должна быть минимизирована относительно параметров модели ученика. Однако, сделать это будет сложно, так как трудно вычислить взаимную информацию.

Вместо этого используется вариационная нижняя граница для каждого члена взаимной информации $I(\bold{t}; \bold{s})$,
в которой определяется вариационное распределение $q(\bold{t}|\bold{s})$, которое аппроксимирует $p(\bold{t}|\bold{s})$:

\begin{multline}
  I(\bold{t}; \bold{s}) = H(\bold{t}) - H(\bold{t} | \bold{s}) =  H(\bold{t}) + \mathbb{E}_{\bold{t},\bold{s}}[\log{p(\bold{t}|\bold{s})}] \\
  + H(\bold{t}) + \mathbb{E}_{\bold{t},\bold{s}}[\log{q(\bold{t}|\bold{s})}] + \mathbb{E}_{\bold{s}}[D_{\text{KL}}(p(\bold{t}|\bold{s})||q(\bold{t}|\bold{s}))] \\
  \geq H(\bold{t}) + \mathbb{E}_{\bold{t},\bold{s}}[\log{q(\bold{t}|\bold{s})}].
\end{multline}

Данная техника известна как вариационная максимизация информации \cite{barber2004algorithm}. Применяя её к каждому члену взаимной информации в функции потерь, получим:

$$ \mathcal{L} = \beta \mathcal{L}_\text{CE} - (1 - \beta){\sum_{i=1}^T \sum_{j=1}^S \lambda_{i, j} \mathbb{E}_{\bold{t},\bold{s}}[\log{q(\bold{t}^{(i)}|\bold{s}^{(j)})}] }.$$

Эта новая функция потерь минимизируется относительно параметров модели ученика и вариационного распределения $q(\bold{t}|\bold{s})$.
Стоит обратить внимание, что энтропия $H(\bold{t})$ убрана из выражения, так как не зависит от оптимизируемых параметров.
Также второй член в функции потерь можно интерпретировать как максимизацию условной вероятности
соответствия активациям выбранных слоев из модели учителя.
Таким образом, сеть учеников получает сжатые знания, необходимые для восстановления активаций выбранных слоев в модели учителя.

Мы выбираем вариационное распределение $q(\bold{t}|\bold{s})$, как нормальное распределение с средним $\bmu(\cdot)$ и
стандратным отклонением $\bsigma$. При этом,  $\bmu(\cdot)$ является функцией от $\bold{s}$, а $\bsigma$ --- нет.
Параметризация  $\bmu(\cdot)$ и $\bsigma$ зависит от типа слоя, которому соответствует $\bold{t}$,
и в процессе дистилляции эти параметры оптимизируются вместе с параметрами модели ученика.

Если $\bold{t}$ соответствует свёрточному слою сети учителя с размерностями активаций, обозначающими канал, высоту и ширину соответственно,
то есть $\bold{t} \in \mathbb{R}^{С \times H \times W}$, вариационное распределение имеет вид:

\begin{multline}
  -\log{q(\bold{t}|\bold{s})} = -\sum_{c=1}^{C}  \sum_{h=1}^{H} \sum_{w=1}^{W} \log{q(t_{c,h,w}|\bold{s})} = \\
  = \sum_{c=1}^{C}  \sum_{h=1}^{H} \sum_{w=1}^{W} \log{\sigma_c} + \frac{(t_{c,h,w} - \mu_{c,h,w}(\bold{s}))^2}{2\sigma_c^2} + constant.
\end{multline}

Рассмотрим все обозначения в данном выражении. Под $t_{c,h,w}$ обозначается скалярный компонент $\bold{t}$, взятый по индексу $(c, h, w)$.
Кроме того, $\bmu(\bold{s})$ представляет собой нейронную сеть из нескольких свёрточных слоёв, на вход которой подаются активации $\bold{s}$ слоя ученика,
а выход имеет размерность, совпадающую с размерностью  $\bold{t}$ слоя учителя. Стандартное отклонение задаём таким образом,
чтобы оно было положительное, в нашем случае:
$$\sigma^2_c = \log{(1 + e^{\alpha_c})} + \epsilon,$$
где $\alpha_c \in \mathbb{R} $ --- обучаемый параметр и $\epsilon$ --- минимальное значение отклонения, заданное для численной устойчивости.

Если $\bold{t}$ соответствует линейному слою сети учителя с размерностью $N$, то есть $\bold{t} \in \mathbb{R}^{N}$,
тогда вариационное распределение имеет вид:

\begin{multline}
  -\log{q(\bold{t}|\bold{s})} = -\sum_{n=1}^{N}  \log{q(t_{n}|\bold{s})} = \\
  = \sum_{n=1}^{N} \log{\sigma_n} + \frac{(t_n - \mu_n(\bold{s}))^2}{2\sigma_n^2} + constant.
\end{multline}

В данном выражении обозначения $t_{n}$ и $\sigma_n$ аналогичны тем, что представлены выше, а $\bmu(\bold{s})$ представляет собой линейную модель,
так же отображающую активации после слоя $\bold{s}$ студента в вектор размерности $N$.

\subsection{Двухуровневая задача оптимизации}

До этого момента мы рассматривали задачу как обычную задачу оптимизации с гиперпараметрами.
Однако, в таком подходе возникают сложности с подбором значений гиперпараметров.
Они могут быть заданы какими-то наивными соображениями, быть подобраны с помощью полного перебора,
с использованием вероятностных моделей \cite{optuna_2019} или с помощью градиентных методов \cite{gorpinich2022gradient}.
Опишем постановку задачи двухуровневой оптимизации.

Разобьём нашу выборку на тренировочную и валидационную: $\mathfrak{D} = \mathfrak{D}_\text{train} \bigsqcup \mathfrak{D}_\text{test}.$
Обозначим $\mathcal{L}_\text{train}$ как функцию потерь $\mathcal{L}$, вычисляемую на выборке $\mathfrak{D}_\text{train}$, а $\mathcal{L}_\text{val}$ ---
как  функцию потерь $\mathcal{L}$, вычисляемую на выборке $\mathfrak{D}_\text{val}$.

Определим вектор $\blambda$ из всех гиперпараметров задачи:
$$\blambda = [\lambda_{0, 0}, \ldots, \lambda_{i, j}, \ldots, \beta].$$

Определим все обучаемые параметры модели ученика и обучаемые параметры взаимной информации как $\bold{w}$.

Заметим, что функции потерь $\mathcal{L}_\text{train}$ и $\mathcal{L}_\text{val}$ зависят и от $\blambda$, и от $\bold{w}$.
Цель --- найти $\hat{\blambda}$, которое минимизирует функцию потерь на валидационной выборке $\mathcal{L}_\text{val}(\bold{\hat{w}}, \hat{\blambda})$, где параметры $\bold{w}$
получаются в результате минимизации функции потерь на тренировочной выборке $\bold{\hat{w}} = \argmin_{\bold{w}}{\mathcal{L}_\text{train}(\bold{w}, \hat{\blambda})}$.

И это определяет задачу двухуровневой оптимизации\cite{darts}:

\begin{equation}
  \begin{aligned}
     & \min_{\blambda} \quad \mathcal{L}_\text{val}(\bold{\hat{w}}(\blambda), \blambda),                               \\
     & \text{s.t.} \quad  \bold{\hat{w}}(\blambda) = \argmin_{\bold{w}}{\mathcal{L}_\text{train}(\bold{w}, \blambda)}.
  \end{aligned}
\end{equation}
